{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"pytorch - GPU\"\n",
        "subtitle: \"Lecture 19\"\n",
        "author: \"Dr. Colin Rundel\"\n",
        "footer: \"Sta 663 - Spring 2025\"\n",
        "format:\n",
        "  revealjs:\n",
        "    theme: slides.scss\n",
        "    transition: fade\n",
        "    slide-number: true\n",
        "    self-contained: true\n",
        "execute: \n",
        "  echo: true\n",
        "engine:\n",
        "    jupyter\n",
        "---"
      ],
      "id": "9532a52d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| include: false\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "\n",
        "import torch\n",
        "\n",
        "import os\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 200\n",
        "\n",
        "torch.set_printoptions(\n",
        "  edgeitems=30, linewidth=46,\n",
        "  precision = 4\n",
        ")\n",
        "\n",
        "np.set_printoptions(\n",
        "  edgeitems=30, linewidth=48,\n",
        "  precision = 5, suppress=True\n",
        ")\n",
        "\n",
        "pd.set_option(\"display.width\", 130)\n",
        "pd.set_option(\"display.max_columns\", 10)\n",
        "pd.set_option(\"display.precision\", 6)"
      ],
      "id": "28b3e6f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{r r_setup}\n",
        "#| include: false\n",
        "knitr::opts_chunk$set(\n",
        "  fig.align=\"center\",\n",
        "  cache=FALSE\n",
        ")\n",
        "\n",
        "local({\n",
        "  hook_err_old <- knitr::knit_hooks$get(\"error\")  # save the old hook\n",
        "  knitr::knit_hooks$set(error = function(x, options) {\n",
        "    # now do whatever you want to do with x, and pass\n",
        "    # the new x to the old hook\n",
        "    x = sub(\"## \\n## Detailed traceback:\\n.*$\", \"\", x)\n",
        "    x = sub(\"Error in py_call_impl\\\\(.*?\\\\)\\\\: \", \"\", x)\n",
        "    #x = stringr::str_wrap(x, width = 100)\n",
        "    hook_err_old(x, options)\n",
        "  })\n",
        "  \n",
        "  hook_warn_old <- knitr::knit_hooks$get(\"warning\")  # save the old hook\n",
        "  knitr::knit_hooks$set(warning = function(x, options) {\n",
        "    x = sub(\"<string>:1: \", \"\", x)\n",
        "    #x = stringr::str_wrap(x, width = 100)\n",
        "    hook_warn_old(x, options)\n",
        "  })\n",
        "  \n",
        "  hook_msg_old <- knitr::knit_hooks$get(\"output\")  # save the old hook\n",
        "  knitr::knit_hooks$set(output = function(x, options) {\n",
        "    if (is.null(options$wrap))\n",
        "      options$wrap = TRUE\n",
        "    \n",
        "    x = stringr::str_replace(x, \"(## ).* ([A-Za-z]+Warning:)\", \"\\\\1\\\\2\")\n",
        "    x = stringr::str_split(x, \"\\n\")[[1]]\n",
        "    #x = stringr::str_wrap(x, width = 120, exdent = 3)\n",
        "    x = stringr::str_remove_all(x, \"\\r\")\n",
        "    if (options$wrap)\n",
        "        x = stringi::stri_wrap(x, width=120, exdent = 3, normalize=FALSE)\n",
        "    x = paste(x, collapse=\"\\n\")\n",
        "    \n",
        "    #x = stringr::str_wrap(x, width = 100)\n",
        "    hook_msg_old(x, options)\n",
        "  })\n",
        "})\n",
        "```\n",
        "\n",
        "\n",
        "## CUDA\n",
        "\n",
        "> CUDA (or Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing unit (GPU) for general purpose processing, an approach called general-purpose computing on GPUs (GPGPU). CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements, for the execution of compute kernels.\n",
        "\n",
        "<br/>\n",
        "\n",
        "Core libraries:\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width='33%'}\n",
        "* cuBLAS\n",
        "\n",
        "* cuSOLVER\n",
        "\n",
        "* cuSPARSE\n",
        ":::\n",
        "\n",
        "::: {.column width='33%'}\n",
        "* cuFFT\n",
        "\n",
        "* cuTENSOR\n",
        "\n",
        "* cuRAND\n",
        ":::\n",
        "\n",
        "::: {.column width='33%'}\n",
        "* Thrust\n",
        "\n",
        "* cuDNN\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "## CUDA Kernels\n",
        "\n",
        "::: {.xsmall}\n",
        "```c\n",
        "// Kernel - Adding two matrices MatA and MatB\n",
        "__global__ void MatAdd(float MatA[N][N], float MatB[N][N], float MatC[N][N])\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if (i < N && j < N)\n",
        "        MatC[i][j] = MatA[i][j] + MatB[i][j];\n",
        "}\n",
        " \n",
        "int main()\n",
        "{\n",
        "    ...\n",
        "    // Matrix addition kernel launch from host code\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks(\n",
        "        (N + threadsPerBlock.x -1) / threadsPerBlock.x, \n",
        "        (N+threadsPerBlock.y -1) / threadsPerBlock.y\n",
        "    );\n",
        "    \n",
        "    MatAdd<<<numBlocks, threadsPerBlock>>>(MatA, MatB, MatC);\n",
        "    ...\n",
        "}\n",
        "```\n",
        ":::\n",
        "\n",
        "\n",
        "##\n",
        "\n",
        "![](imgs/gpu_bench1.png){fig-align=\"center\" width=\"100%\"}\n",
        "\n",
        "\n",
        "##\n",
        "\n",
        "![](imgs/gpu_bench2.png){fig-align=\"center\" width=\"100%\"}\n",
        "\n",
        "## GPU Status\n",
        "\n",
        "::: {.xsmall}\n",
        "\n",
        "```{bash smi}\n",
        "nvidia-smi\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "## Torch GPU Information\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "299fea7b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "torch.cuda.is_available()\n",
        "\n",
        "torch.cuda.device_count()\n",
        "\n",
        "torch.cuda.get_device_name(\"cuda:0\")\n",
        "torch.cuda.get_device_name(\"cuda:1\")\n",
        "\n",
        "torch.cuda.get_device_properties(0)\n",
        "torch.cuda.get_device_properties(1)"
      ],
      "id": "067144e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## GPU Tensors\n",
        "\n",
        "Usage of the GPU is governed by the location of the Tensors - to use the GPU we allocate them on the GPU device.\n",
        "\n",
        ":::: {.columns .xsmall}\n",
        "::: {.column width='50%'}"
      ],
      "id": "e7e184e0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cpu = torch.device('cpu')\n",
        "cuda0 = torch.device('cuda:0')\n",
        "cuda1 = torch.device('cuda:1')\n",
        "\n",
        "x = torch.linspace(0,1,5, device=cuda0); x\n",
        "y = torch.randn(5,2, device=cuda0); y\n",
        "z = torch.rand(2,3, device=cpu); z"
      ],
      "id": "4b545593",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column width='50%' .fragment}"
      ],
      "id": "e54dde10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| error: true\n",
        "x @ y\n",
        "y @ z\n",
        "y @ z.to(cuda0)"
      ],
      "id": "1d221c74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## NN Layers + GPU\n",
        "\n",
        "NN layers (parameters) also need to be assigned to the GPU to be used with GPU tensors,\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "f13cc5bb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| error: true\n",
        "nn = torch.nn.Linear(5,5)\n",
        "X = torch.randn(10,5).cuda()"
      ],
      "id": "9982dd54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "46dba4a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| error: true\n",
        "nn(X)"
      ],
      "id": "d9f4108d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        ":::: {.columns .xsmall}\n",
        "::: {.column width='50%'}"
      ],
      "id": "a9837615"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nn.cuda()(X)"
      ],
      "id": "5ee933b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column width='50%'}"
      ],
      "id": "176b5982"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nn.to(device=\"cuda\")(X)"
      ],
      "id": "9c765ee4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## Back to MNIST\n",
        "\n",
        "Same MNIST data from last time (1x8x8 images),\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "d3d70557"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, shuffle=True, random_state=1234\n",
        ")\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train)\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test)"
      ],
      "id": "8469bc02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "To use the GPU for computation we need to copy these tensors to the GPU,\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "607339a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_cuda = X_train.to(device=cuda0)\n",
        "y_train_cuda = y_train.to(device=cuda0)\n",
        "X_test_cuda = X_test.to(device=cuda0)\n",
        "y_test_cuda = y_test.to(device=cuda0)"
      ],
      "id": "5b3c80a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## Convolutional NN\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "45589e9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class mnist_conv_model(torch.nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.device = torch.device(device)\n",
        "        \n",
        "        self.model = torch.nn.Sequential(\n",
        "          torch.nn.Unflatten(1, (1,8,8)),\n",
        "          torch.nn.Conv2d(\n",
        "            in_channels=1, out_channels=8,\n",
        "            kernel_size=3, stride=1, padding=1\n",
        "          ),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.MaxPool2d(kernel_size=2),\n",
        "          torch.nn.Flatten(),\n",
        "          torch.nn.Linear(8 * 4 * 4, 10)\n",
        "        ).to(device=self.device)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.model(X)\n",
        "    \n",
        "    def fit(self, X, y, lr=0.001, n=1000, acc_step=10):\n",
        "      opt = torch.optim.SGD(self.parameters(), lr=lr, momentum=0.9) \n",
        "      losses = []\n",
        "      for i in range(n):\n",
        "          opt.zero_grad()\n",
        "          loss = torch.nn.CrossEntropyLoss()(self(X), y)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "          losses.append(loss.item())\n",
        "      \n",
        "      return losses\n",
        "    \n",
        "    def accuracy(self, X, y):\n",
        "      val, pred = torch.max(self(X), dim=1)\n",
        "      return( (pred == y).sum() / len(y) )"
      ],
      "id": "d18b6837",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## CPU vs Cuda\n",
        "\n",
        ":::: {.columns .xsmall}\n",
        "::: {.column width='50%'}"
      ],
      "id": "f75a7a51"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = mnist_conv_model(device=\"cpu\")\n",
        "loss = m.fit(X_train, y_train, n=1000)\n",
        "loss[-1]\n",
        "m.accuracy(X_test, y_test)"
      ],
      "id": "f1255d7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column width='50%'}"
      ],
      "id": "9ed10d63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m_cuda = mnist_conv_model(device=\"cuda\")\n",
        "loss = m_cuda.fit(X_train_cuda, y_train_cuda, n=1000)\n",
        "loss[-1]\n",
        "m_cuda.accuracy(X_test_cuda, y_test_cuda)"
      ],
      "id": "7d5b32e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "## Performance\n",
        "\n",
        ":::: {.columns .xsmall}\n",
        "::: {.column width='50%'}\n",
        "CPU performance:"
      ],
      "id": "1c53586f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = mnist_conv_model(device=\"cpu\")\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start.record()\n",
        "loss = m.fit(X_train, y_train, n=1000)\n",
        "end.record()\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "print(start.elapsed_time(end) / 1000) "
      ],
      "id": "d1ae52f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column width='50%'}\n",
        "GPU performance:"
      ],
      "id": "9184de25"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m_cuda = mnist_conv_model(device=\"cuda\")\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start.record()\n",
        "loss = m_cuda.fit(X_train_cuda, y_train_cuda, n=1000)\n",
        "end.record()\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "print(start.elapsed_time(end) / 1000) "
      ],
      "id": "9966e83c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## Profiling CPU - 1 forward step\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "fd3f8fb5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = mnist_conv_model(device=\"cpu\")\n",
        "with torch.autograd.profiler.profile(with_stack=True, profile_memory=True) as prof_cpu:\n",
        "    tmp = m(X_train)"
      ],
      "id": "a4cea3b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cpu.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "b90dd1c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Profiling GPU - 1 forward step\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "f05bdbb0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m_cuda = mnist_conv_model(device=\"cuda\")\n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_cuda:\n",
        "    tmp = m_cuda(X_train_cuda)"
      ],
      "id": "119ef995",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cuda.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "8fcf4317",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## Profiling CPU - fit\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "3325c072"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = mnist_conv_model(device=\"cpu\")\n",
        "with torch.autograd.profiler.profile(with_stack=True, profile_memory=True) as prof_cpu:\n",
        "    losses = m.fit(X_train, y_train, n=1000)"
      ],
      "id": "7b782d1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cpu.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "1697a6d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Profiling GPU - fit\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "8fd836e4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m_cuda = mnist_conv_model(device=\"cuda\")\n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_cuda:\n",
        "    losses = m_cuda.fit(X_train_cuda, y_train_cuda, n=1000)"
      ],
      "id": "c45220c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cuda.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "16925d9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "# CIFAR10\n",
        "\n",
        "<br/>\n",
        "\n",
        "::: {.xsmall}\n",
        "[homepage](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        ":::\n",
        "\n",
        "## Loading the data\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "1984571d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "training_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"/data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"/data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")"
      ],
      "id": "8e642ec7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## CIFAR10 data\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "8b5386b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "training_data.classes\n",
        "training_data.data.shape\n",
        "test_data.data.shape"
      ],
      "id": "69216bde",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "55204397"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "training_data[0]"
      ],
      "id": "4e2de4ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Example data\n"
      ],
      "id": "5807eedc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(10, 6), layout=\"constrained\")\n",
        "\n",
        "for i, ax in enumerate([ax for row in axes for ax in row]):\n",
        "    ax.set_axis_off()\n",
        "    img, cls = training_data[i]\n",
        "    \n",
        "    p = ax.imshow(img.numpy().transpose((1,2,0)))\n",
        "    t = ax.set_title(f\"{training_data.classes[cls]}\")\n",
        "    \n",
        "plt.show()"
      ],
      "id": "4d1f2440",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loaders\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "0b233cc5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "batch_size = 100\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(\n",
        "    training_data, \n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, \n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "id": "671b1a8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Loader generator\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "153d4a3b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "training_loader"
      ],
      "id": "1b4c9e06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "21f0dc36"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X, y = next(iter(training_loader))\n",
        "X.shape\n",
        "y.shape"
      ],
      "id": "77341b1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## CIFAR CNN\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "a9301900"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class cifar_conv_model(torch.nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.device = torch.device(device)\n",
        "        self.epoch = 0\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 6, kernel_size=5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(2, 2),\n",
        "            torch.nn.Conv2d(6, 16, kernel_size=5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(2, 2),\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(16 * 5 * 5, 120),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(120, 84),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(84, 10)\n",
        "        ).to(device=self.device)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.model(X)\n",
        "    \n",
        "    def fit(self, loader, epochs=10, n_report=250, lr=0.001):\n",
        "        opt = torch.optim.SGD(self.parameters(), lr=lr, momentum=0.9) \n",
        "      \n",
        "        for j in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            for i, (X, y) in enumerate(loader):\n",
        "                X, y = X.to(self.device), y.to(self.device)\n",
        "                opt.zero_grad()\n",
        "                loss = torch.nn.CrossEntropyLoss()(self(X), y)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "    \n",
        "                # print statistics\n",
        "                running_loss += loss.item()\n",
        "                if i % n_report == (n_report-1):    # print every 100 mini-batches\n",
        "                    print(f'[Epoch {self.epoch + 1}, Minibatch {i + 1:4d}] loss: {running_loss / n_report:.3f}')\n",
        "                    running_loss = 0.0\n",
        "            \n",
        "            self.epoch += 1"
      ],
      "id": "e7d520dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.aside}\n",
        "Based on [PyTorch cifar10 tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
        ":::\n",
        "\n",
        "\n",
        "## CNN Performance - CPU (1 step)\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "205f756e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| error: true\n",
        "X, y = next(iter(training_loader))\n",
        "\n",
        "m_cpu = cifar_conv_model(device=\"cpu\")\n",
        "tmp = m_cpu(X)\n",
        "\n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_cpu:\n",
        "    tmp = m_cpu(X)"
      ],
      "id": "375f7fb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-overflow: scroll\n",
        "print(prof_cpu.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "fb3c9edf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## CNN Performance - GPU (1 step)\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "7c90d3f3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m_cuda = cifar_conv_model(device=\"cuda\")\n",
        "Xc, yc = X.to(device=\"cuda\"), y.to(device=\"cuda\")\n",
        "tmp = m_cuda(Xc)\n",
        "    \n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_cuda:\n",
        "    tmp = m_cuda(Xc)"
      ],
      "id": "4d68ca8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cuda.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "ee1b050f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## CNN Performance - CPU (1 epoch)\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "9c92d4b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| error: true\n",
        "m_cpu = cifar_conv_model(device=\"cpu\")\n",
        "\n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_cpu:\n",
        "    m_cpu.fit(loader=training_loader, epochs=1, n_report=501)"
      ],
      "id": "2fe7a099",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cpu.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "4667b8e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## CNN Performance - GPU (1 epoch)\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "0de0d33d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m_cuda = cifar_conv_model(device=\"cuda\")\n",
        "\n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_cuda:\n",
        "    m_cuda.fit(loader=training_loader, epochs=1, n_report=501)"
      ],
      "id": "bd21012a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cuda.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "49fce6cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Loaders & Accuracy\n"
      ],
      "id": "71a79f74"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def accuracy(model, loader, device):\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in loader:\n",
        "            X, y = X.to(device=device), y.to(device=device)\n",
        "            pred = model(X)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            val, idx = torch.max(pred, 1)\n",
        "            total += pred.size(0)\n",
        "            correct += (idx == y).sum().item()\n",
        "            \n",
        "    return correct / total"
      ],
      "id": "5366e6f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model fitting\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "b3d2d833"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = cifar_conv_model(\"cuda\")\n",
        "m.fit(training_loader, epochs=10, n_report=500, lr=0.01)\n",
        "## [Epoch 1, Minibatch  500] loss: 2.098\n",
        "## [Epoch 2, Minibatch  500] loss: 1.692\n",
        "## [Epoch 3, Minibatch  500] loss: 1.482\n",
        "## [Epoch 4, Minibatch  500] loss: 1.374\n",
        "## [Epoch 5, Minibatch  500] loss: 1.292\n",
        "## [Epoch 6, Minibatch  500] loss: 1.226\n",
        "## [Epoch 7, Minibatch  500] loss: 1.173\n",
        "## [Epoch 8, Minibatch  500] loss: 1.117\n",
        "## [Epoch 9, Minibatch  500] loss: 1.071\n",
        "## [Epoch 10, Minibatch  500] loss: 1.035"
      ],
      "id": "da1063f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "2c237df8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "accuracy(m, training_loader, \"cuda\")\n",
        "## 0.63444\n",
        "accuracy(m, test_loader, \"cuda\")\n",
        "## 0.572"
      ],
      "id": "04a16546",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## More epochs\n",
        "\n",
        "If continue fitting with the existing model,\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "7b718e7c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m.fit(training_loader, epochs=10, n_report=500)\n",
        "## [Epoch 11, Minibatch  500] loss: 0.885\n",
        "## [Epoch 12, Minibatch  500] loss: 0.853\n",
        "## [Epoch 13, Minibatch  500] loss: 0.839\n",
        "## [Epoch 14, Minibatch  500] loss: 0.828\n",
        "## [Epoch 15, Minibatch  500] loss: 0.817\n",
        "## [Epoch 16, Minibatch  500] loss: 0.806\n",
        "## [Epoch 17, Minibatch  500] loss: 0.798\n",
        "## [Epoch 18, Minibatch  500] loss: 0.787\n",
        "## [Epoch 19, Minibatch  500] loss: 0.780\n",
        "## [Epoch 20, Minibatch  500] loss: 0.773"
      ],
      "id": "f1cad151",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "accuracy(m, training_loader, \"cuda\")\n",
        "## 0.73914\n",
        "accuracy(m, test_loader, \"cuda\")\n",
        "## 0.624"
      ],
      "id": "73dc6c41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## More epochs (again)\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "e599ce63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m.fit(training_loader, epochs=10, n_report=500)\n",
        "## [Epoch 21, Minibatch  500] loss: 0.764\n",
        "## [Epoch 22, Minibatch  500] loss: 0.756\n",
        "## [Epoch 23, Minibatch  500] loss: 0.748\n",
        "## [Epoch 24, Minibatch  500] loss: 0.739\n",
        "## [Epoch 25, Minibatch  500] loss: 0.733\n",
        "## [Epoch 26, Minibatch  500] loss: 0.726\n",
        "## [Epoch 27, Minibatch  500] loss: 0.718\n",
        "## [Epoch 28, Minibatch  500] loss: 0.710\n",
        "## [Epoch 29, Minibatch  500] loss: 0.702\n",
        "## [Epoch 30, Minibatch  500] loss: 0.698"
      ],
      "id": "9672fe80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "accuracy(m, training_loader, \"cuda\")\n",
        "## 0.76438\n",
        "accuracy(m, test_loader, \"cuda\")\n",
        "## 0.6217"
      ],
      "id": "b8c6e0d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## The VGG16 model\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "44b8b498"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class VGG16(torch.nn.Module):\n",
        "    def make_layers(self):\n",
        "        cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [torch.nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [torch.nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           torch.nn.BatchNorm2d(x),\n",
        "                           torch.nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [\n",
        "            torch.nn.AvgPool2d(kernel_size=1, stride=1),\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(512,10)\n",
        "        ]\n",
        "        \n",
        "        return torch.nn.Sequential(*layers).to(self.device)\n",
        "    \n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.device = torch.device(device)\n",
        "        self.model = self.make_layers()\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.model(X)"
      ],
      "id": "2e88a174",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.aside}\n",
        "Based on code from [pytorch-cifar](https://github.com/kuangliu/pytorch-cifar), original [paper](https://arxiv.org/abs/1409.1556)\n",
        ":::\n",
        "\n",
        "## Model\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "859f2736"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "VGG16(\"cpu\").model"
      ],
      "id": "450630b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## VGG16 performance - CPU\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "93f11afd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X, y = next(iter(training_loader))\n",
        "m_cpu = VGG16(device=\"cpu\")\n",
        "tmp = m_cpu(X)\n",
        "\n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_cpu:\n",
        "    tmp = m_cpu(X)"
      ],
      "id": "40f25be5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cpu.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "1f6ebd4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## VGG16 performance - GPU\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "73abc249"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m_cuda = VGG16(device=\"cuda\")\n",
        "Xc, yc = X.to(device=\"cuda\"), y.to(device=\"cuda\")\n",
        "tmp = m_cuda(Xc)\n",
        "\n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_cuda:\n",
        "    tmp = m_cuda(Xc)"
      ],
      "id": "9b8b3bcf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(prof_cuda.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "6543d911",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## VGG16 performance - Apple M1 GPU (mps)\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "5414f03e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "m_mps = VGG16(device=\"mps\")\n",
        "Xm, ym = X.to(device=\"mps\"), y.to(device=\"mps\")\n",
        "\n",
        "with torch.autograd.profiler.profile(with_stack=True) as prof_mps:\n",
        "    tmp = m_mps(Xm)"
      ],
      "id": "66e49958",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "print(prof_mps.key_averages().table(sort_by='self_cpu_time_total', row_limit=5))"
      ],
      "id": "8cadaf59",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
        "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
        "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
        "         aten::native_batch_norm        35.71%       3.045ms        35.71%       3.045ms     234.231us            13  \n",
        "          aten::_mps_convolution        19.67%       1.677ms        19.88%       1.695ms     130.385us            13  \n",
        "    aten::_batch_norm_impl_index        11.92%       1.016ms        36.02%       3.071ms     236.231us            13  \n",
        "                     aten::relu_        11.29%     963.000us        11.29%     963.000us      74.077us            13  \n",
        "                      aten::add_        10.40%     887.000us        10.44%     890.000us      68.462us            13  \n",
        "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
        "Self CPU time total: 8.526ms\n",
        "```\n",
        ":::\n",
        "\n",
        "\n",
        "## Fitting w/ `lr = 0.01`\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "861156e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = VGG16(device=\"cuda\")\n",
        "fit(m, training_loader, epochs=10, n_report=500, lr=0.01)\n",
        "\n",
        "## [Epoch 1, Minibatch  500] loss: 1.345\n",
        "## [Epoch 2, Minibatch  500] loss: 0.790\n",
        "## [Epoch 3, Minibatch  500] loss: 0.577\n",
        "## [Epoch 4, Minibatch  500] loss: 0.445\n",
        "## [Epoch 5, Minibatch  500] loss: 0.350\n",
        "## [Epoch 6, Minibatch  500] loss: 0.274\n",
        "## [Epoch 7, Minibatch  500] loss: 0.215\n",
        "## [Epoch 8, Minibatch  500] loss: 0.167\n",
        "## [Epoch 9, Minibatch  500] loss: 0.127\n",
        "## [Epoch 10, Minibatch  500] loss: 0.103"
      ],
      "id": "32241987",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "474c5634"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "accuracy(model=m, loader=training_loader, device=\"cuda\")\n",
        "## 0.97008\n",
        "accuracy(model=m, loader=test_loader, device=\"cuda\")\n",
        "## 0.8318"
      ],
      "id": "a1949a3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## Fitting w/ `lr = 0.001`\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "30e0de24"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = VGG16(device=\"cuda\")\n",
        "fit(m, training_loader, epochs=10, n_report=500, lr=0.001)\n",
        "\n",
        "## [Epoch 1, Minibatch  500] loss: 1.279\n",
        "## [Epoch 2, Minibatch  500] loss: 0.827\n",
        "## [Epoch 3, Minibatch  500] loss: 0.599\n",
        "## [Epoch 4, Minibatch  500] loss: 0.428\n",
        "## [Epoch 5, Minibatch  500] loss: 0.303\n",
        "## [Epoch 6, Minibatch  500] loss: 0.210\n",
        "## [Epoch 7, Minibatch  500] loss: 0.144\n",
        "## [Epoch 8, Minibatch  500] loss: 0.108\n",
        "## [Epoch 9, Minibatch  500] loss: 0.088\n",
        "## [Epoch 10, Minibatch  500] loss: 0.063"
      ],
      "id": "9aac234a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "9520a0f6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "accuracy(model=m, loader=training_loader, device=\"cuda\")\n",
        "## 0.9815\n",
        "accuracy(model=m, loader=test_loader, device=\"cuda\")\n",
        "## 0.7816"
      ],
      "id": "1b1f5058",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Report\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "5bc6d09d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def report(model, loader, device):\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in loader:\n",
        "            X = X.to(device=device)\n",
        "            y_true.append( y.cpu().numpy() )\n",
        "            y_pred.append( model(X).max(1)[1].cpu().numpy() )\n",
        "    \n",
        "    y_true = np.concatenate(y_true)\n",
        "    y_pred = np.concatenate(y_pred)\n",
        "\n",
        "    return classification_report(y_true, y_pred, target_names=loader.dataset.classes)"
      ],
      "id": "17728db2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "##\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "0596205b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "print(report(model=m, loader=test_loader, device=\"cuda\"))\n",
        "\n",
        "##               precision    recall  f1-score   support\n",
        "## \n",
        "##     airplane       0.82      0.88      0.85      1000\n",
        "##   automobile       0.95      0.89      0.92      1000\n",
        "##         bird       0.85      0.70      0.77      1000\n",
        "##          cat       0.68      0.74      0.71      1000\n",
        "##         deer       0.84      0.83      0.83      1000\n",
        "##          dog       0.81      0.73      0.77      1000\n",
        "##         frog       0.83      0.92      0.87      1000\n",
        "##        horse       0.87      0.87      0.87      1000\n",
        "##         ship       0.89      0.92      0.90      1000\n",
        "##        truck       0.86      0.93      0.89      1000\n",
        "## \n",
        "##     accuracy                           0.84     10000\n",
        "##    macro avg       0.84      0.84      0.84     10000\n",
        "## weighted avg       0.84      0.84      0.84     10000"
      ],
      "id": "0de4716f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "# Some state-of-the-art examples\n",
        "\n",
        "## Hugging Face\n",
        "\n",
        "This is an online community and platform for sharing machine learning models (architectures and weights), data, and related artifacts. They also maintain a number of packages and related training materials that help with building, training, and deploying ML models.\n",
        "\n",
        "Some notable resources,\n",
        "\n",
        "* [`transformers`](https://huggingface.co/docs/transformers/index) - APIs and tools to easily download and train state-of-the-art (pretrained) transformer based models \n",
        "\n",
        "* [`diffusers`](https://huggingface.co/docs/diffusers/index) - provides pretrained vision and audio diffusion models, and serves as a modular toolbox for inference and training\n",
        "\n",
        "* [`timm`](https://huggingface.co/docs/timm/index) - a library containing SOTA computer vision models, layers, utilities, optimizers, schedulers, data-loaders, augmentations, and training/evaluation scripts\n",
        "\n",
        "\n",
        "## Stable Diffusion\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "2af246ab"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false,
        "results": "hide"
      },
      "source": [
        "#| warning: false\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "  \"stabilityai/stable-diffusion-2-1-base\", torch_dtype=torch.float16\n",
        ").to(\"cuda\")"
      ],
      "id": "bf6502ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "4ba1bd0c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide",
        "cache": true
      },
      "source": [
        "prompt = \"a picture of thomas bayes with a cat on his lap\"\n",
        "generator = [torch.Generator(device=\"cuda\").manual_seed(i) for i in range(6)]\n",
        "fit = pipe(prompt, generator=generator, num_inference_steps=20, num_images_per_prompt=6)"
      ],
      "id": "f72c833b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "9b3c7a4a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "fit.images"
      ],
      "id": "e8f19e08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "##\n"
      ],
      "id": "65e03c9b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 6), layout=\"constrained\")\n",
        "\n",
        "for i, ax in enumerate([ax for row in axes for ax in row]):\n",
        "    ax.set_axis_off()\n",
        "    p = ax.imshow(fit.images[i])\n",
        "    \n",
        "plt.show()"
      ],
      "id": "bc21995f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.aside}\n",
        "[Thomas Bayes GIS](https://www.google.com/search?q=thomas+bayes&source=lnms&tbm=isch&sa=X&biw=1280&bih=590&dpr=2)\n",
        ":::\n",
        "\n",
        "\n",
        "## Customizing prompts\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "f08e2d63"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide",
        "cache": true
      },
      "source": [
        "prompt = \"a picture of thomas bayes with a cat on his lap\"\n",
        "prompts = [\n",
        "  prompt + t for t in \n",
        "  [\"in the style of a japanese wood block print\",\n",
        "   \"as a hipster with facial hair and glasses\",\n",
        "   \"as a simpsons character, cartoon, yellow\",\n",
        "   \"in the style of a vincent van gogh painting\",\n",
        "   \"in the style of a picasso painting\",\n",
        "   \"with flowery wall paper\"\n",
        "  ]\n",
        "]\n",
        "\n",
        "generator = [torch.Generator(device=\"cuda\").manual_seed(i) for i in range(6)]\n",
        "fit = pipe(prompts, generator=generator, num_inference_steps=20, num_images_per_prompt=1)"
      ],
      "id": "804b1813",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## \n"
      ],
      "id": "de1b35ae"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 6), layout=\"constrained\")\n",
        "\n",
        "for i, ax in enumerate([ax for row in axes for ax in row]):\n",
        "    ax.set_axis_off()\n",
        "    p = ax.imshow(fit.images[i])\n",
        "    \n",
        "plt.show()"
      ],
      "id": "64424d22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Increasing inference steps\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "b066f265"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide",
        "cache": true
      },
      "source": [
        "generator = [torch.Generator(device=\"cuda\").manual_seed(i) for i in range(6)]\n",
        "fit = pipe(prompts, generator=generator, num_inference_steps=50, num_images_per_prompt=1)"
      ],
      "id": "cdbed0ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n"
      ],
      "id": "d8006f8f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 6), layout=\"constrained\")\n",
        "\n",
        "for i, ax in enumerate([ax for row in axes for ax in row]):\n",
        "    ax.set_axis_off()\n",
        "    p = ax.imshow(fit.images[i])\n",
        "    \n",
        "plt.show()"
      ],
      "id": "78055fad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alpaca LoRA\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "8664207a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "from transformers import GenerationConfig, LlamaTokenizer, LlamaForCausalLM\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"chainyo/alpaca-lora-7b\")\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    \"chainyo/alpaca-lora-7b\",\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=0.2,\n",
        "    top_p=0.75,\n",
        "    top_k=40,\n",
        "    num_beams=4,\n",
        "    max_new_tokens=128,\n",
        ")"
      ],
      "id": "481386b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.aside}\n",
        "Based on [chainyo/alpaca-lora-7b](https://huggingface.co/chainyo/alpaca-lora-7b), see also [alpaca lora](https://github.com/tloen/alpaca-lora), [stanform alpaca](https://github.com/tatsu-lab/stanford_alpaca) & [llama](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)\n",
        ":::\n",
        "\n",
        "## Generate a prompt\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "edd6ead0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| include: false\n",
        "def generate_prompt(instruction, input_ctxt = None):\n",
        "    if input_ctxt:\n",
        "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{input_ctxt}\n",
        "\n",
        "### Response:\"\"\"\n",
        "    else:\n",
        "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Response:\"\"\""
      ],
      "id": "3b4ca464",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "instruction = \"Write a short childrens story about Thomas Bayes and his pet cat\"\n",
        "input_ctxt = None \n",
        "prompt = generate_prompt(instruction, input_ctxt)\n",
        "print(prompt)"
      ],
      "id": "2fdbb9ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Write a short childrens story about Thomas Bayes and his pet cat\n",
        "\n",
        "### Response:\n",
        "```\n",
        ":::\n",
        "\n",
        "\n",
        "## Running the model\n",
        "\n",
        "::: {.xsmall}"
      ],
      "id": "4643eedf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        generation_config=generation_config,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "id": "7f3b5430",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Write a short childrens story about Thomas Bayes and his pet cat\n",
        "\n",
        "### Response:\n",
        "Once upon a time, there was a little boy named Thomas Bayes. He had a pet cat named Fluffy, and \n",
        "they were the best of friends. One day, Thomas and Fluffy decided to go on an adventure. They \n",
        "traveled far and wide, exploring new places and meeting new people. Along the way, Thomas and \n",
        "Fluffy learned many valuable lessons, such as the importance of friendship and the joy of discovery.\n",
        "Eventually, Thomas and Fluffy made their way back home, where they were welcomed with open arms. \n",
        "Thomas and Fluffy had a wonderful time.\n",
        "```\n",
        ":::"
      ],
      "id": "52abca16"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}